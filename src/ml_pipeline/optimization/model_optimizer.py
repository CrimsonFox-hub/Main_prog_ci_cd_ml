"""
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π: Quantization –∏ Pruning
–≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –∫ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏
"""
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
import onnx
import onnxruntime as ort
import numpy as np
import json
from pathlib import Path
import time

class ModelOptimizer:
    def __init__(self, model_path, input_size):
        self.model_path = model_path
        self.input_size = input_size
        
    def dynamic_quantization(self, model):
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ 8-bit"""
        print("üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è (INT8)...")
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ
        quantized_model = torch.quantization.quantize_dynamic(
            model,
            {nn.Linear, nn.BatchNorm1d},
            dtype=torch.qint8
        )
        
        return quantized_model
    
    def static_quantization(self, model, calibration_data):
        """–°—Ç–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π"""
        print("üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è (INT8)...")
        
        model.eval()
        model.qconfig = torch.quantization.get_default_qconfig('fbgemm')
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
        model_prepared = torch.quantization.prepare(model)
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
        print("   –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞ 100 –ø—Ä–∏–º–µ—Ä–∞—Ö...")
        with torch.no_grad():
            for i in range(100):
                dummy_input = calibration_data[i:i+1]
                _ = model_prepared(dummy_input)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        model_quantized = torch.quantization.convert(model_prepared)
        
        return model_quantized
    
    def apply_pruning(self, model, pruning_rate=0.2):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ pruning –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        print(f"‚úÇÔ∏è  –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ pruning ({pruning_rate*100}% –≤–µ—Å–æ–≤)...")
        
        parameters_to_prune = []
        for name, module in model.named_modules():
            if isinstance(module, nn.Linear):
                parameters_to_prune.append((module, 'weight'))
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º L1 unstructured pruning
        for module, param_name in parameters_to_prune:
            prune.l1_unstructured(module, name=param_name, amount=pruning_rate)
        
        # –£–¥–∞–ª—è–µ–º –º–∞—Å–∫–∏ pruning –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
        for module, param_name in parameters_to_prune:
            prune.remove(module, param_name)
        
        return model
    
    def optimize_onnx_model(self, onnx_path):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏"""
        print("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏...")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏
        model = onnx.load(onnx_path)
        
        # –ë–∞–∑–æ–≤—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        from onnxruntime.transformers import optimizer
        
        optimized_model = optimizer.optimize_model(
            onnx_path,
            model_type='bert',
            num_heads=1,
            hidden_size=self.input_size
        )
        
        optimized_path = onnx_path.replace('.onnx', '_optimized.onnx')
        optimized_model.save_model_to_file(optimized_path)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
        original_size = Path(onnx_path).stat().st_size / 1024
        optimized_size = Path(optimized_path).stat().st_size / 1024
        
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {original_size:.1f} KB")
        print(f"   –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {optimized_size:.1f} KB")
        print(f"   –£–º–µ–Ω—å—à–µ–Ω–∏–µ: {(1 - optimized_size/original_size)*100:.1f}%")
        
        return optimized_path
    
    def benchmark_optimization(self, original_model, optimized_model, test_data):
        """–ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        print("üìä –ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        
        results = []
        
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        original_model.eval()
        start = time.time()
        with torch.no_grad():
            for i in range(0, len(test_data), 100):
                batch = test_data[i:i+100]
                _ = original_model(batch)
        original_time = time.time() - start
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        optimized_model.eval()
        start = time.time()
        with torch.no_grad():
            for i in range(0, len(test_data), 100):
                batch = test_data[i:i+100]
                _ = optimized_model(batch)
        optimized_time = time.time() - start
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–∫–∏)
        if hasattr(test_data, 'labels'):
            with torch.no_grad():
                outputs_original = original_model(test_data.features[:100])
                outputs_optimized = optimized_model(test_data.features[:100])
            
            mae = torch.mean(torch.abs(outputs_original - outputs_optimized)).item()
            print(f"   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {mae:.6f}")
        else:
            mae = None
        
        results = {
            'original_inference_time_ms': original_time / len(test_data) * 1000,
            'optimized_inference_time_ms': optimized_time / len(test_data) * 1000,
            'speedup_ratio': original_time / optimized_time,
            'mean_absolute_error': mae,
            'memory_reduction_percentage': None  # –ù—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
        }
        
        print(f"   –£—Å–∫–æ—Ä–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {results['speedup_ratio']:.2f}x")
        
        return results
    
    def create_optimization_report(self, results, output_path='reports/optimization_report.json'):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        report = {
            'optimization_date': time.strftime('%Y-%m-%d %H:%M:%S'),
            'input_size': self.input_size,
            'optimization_results': results,
            'recommendations': []
        }
        
        if results.get('speedup_ratio', 1) > 1.5:
            report['recommendations'].append("‚úÖ –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ")
        
        if results.get('mean_absolute_error', 0) < 0.01:
            report['recommendations'].append("‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–∏–ª–∞—Å—å –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        
        return report

def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    import yaml
    from src.ml_pipeline.training.train_model import CreditScoringNN
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('configs/training_config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    input_size = 20  # –ü—Ä–∏–º–µ—Ä: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    model = CreditScoringNN(input_size)
    model.load_state_dict(torch.load(config['model_paths']['final_model']))
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = ModelOptimizer(
        model_path=config['model_paths']['final_model'],
        input_size=input_size
    )
    
    # 1. Pruning
    pruned_model = optimizer.apply_pruning(model, pruning_rate=0.2)
    
    # 2. Dynamic Quantization
    quantized_model = optimizer.dynamic_quantization(pruned_model)
    
    # 3. –ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥
    test_data = torch.randn(1000, input_size)
    results = optimizer.benchmark_optimization(model, quantized_model, test_data)
    
    # 4. –û—Ç—á–µ—Ç
    optimizer.create_optimization_report(results)
    
    print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main()